\chapter{Materials and Methods}
\section{Experimental Design}
All the data analyzed in this elaborate derives from cellular samples obtained and processed within the Pagani laboratory. Samples were collected frompatients of both \textit{San Paolo Hospital} in Milan and \textit{Humanitas Research Hospital} in Rozzano. The whole dataset consists of 53 samples, obtained from 11 patients, 3 of which diagnosed with Colorectal Cancer (\textit{CRC}) while 7 diagnosed with Non Small Cell Lung Cancer (\textit{NSCLC}). From each patient, cells were sampled from tumoral tissue, normal tissue adjacent to the tumor and peripheral blood. One additional blood sample from an healthy donor was included in the study as well.\\
Five different cell types of interest were isolated with Fluorescence-activated cell sorting (FACS) using the following markers:\\

% Table with cell populations and markers for facs
\begin{center}
\begin{tabular}{c|c}
\hline
\textbf{Population} & \textbf{Markers} \\
\hline
CD4 Conventional T cells (Tconv) & CD3+ CD4+ CD45RO+ \\
CD4 T regulatory (Treg) & CD4+ CD25+ CD127dim \\
CD4 Type 1 regulatory T cells (Tr1) & CD3+ CD4+ CD27+ CD195+ \\ 
CD8 Memory T cells (Tmem) & CD3+ CD8+ CD45RO+ TIM3- CD39- \\
CD8 Exhausted T cells (Texh) & CD3+ CD8+ CD45RO+ TIM3+ CD39+ \\
\hline
\end{tabular}
\end{center}

Treg and Tr1 populations were representative of both CRC and NSCLC, while Tconv cells and both CD8+ populations were taken exclusively from NSCLC patients. At least two biological replicates were included for both the tumor and the normal counterpart for each cell type.\\
A standard ATAC-seq protocol, as described in \textit{Buenrostro et al.}\cite{Buenrostro2015}, was then applied to all 53 samples, starting with 5000 cells for each experiment. After tagmentation, libraries were built by PCR amplification and then sequenced through the Illumina HiSeq4000 platform. Paired-end sequencing was run with a read length of 125bp and an average sequencing depth of 240 million reads for each library.
The initial data-analysis steps (i.e. sequencing quality control, read trimming, read alignment, duplicate detection and peak calling) were carried out within a standardized analytical pipeline for bulk ATAC-seq provided by the nf-core community\cite{Ewels2020} and openly available on GitHub. 

\section{The ATAC-seq Pipeline}
The ATAC-seq pipeline used in the initial steps of data analysis is written in Nextflow\cite{DiTommaso2017}, a portable pipeline management system which simplifies the process of building integrated analytical pipelines by providing a standardized data-flow paradigm. Also, thanks to the integration with containerization technologies such as Docker and Singularity\cite{Kurtzer2017}, Nextflow-based projects ensure reproducibility.

\section{Sequencing Quality Control}
After the generation of reads, a crucial part of any Next Generation Sequencing (hereafter referred to as \textit{NGS}) analytical pipeline is to check the quality of each read by assessing the likelihood that each base composing the read was correctly called by the sequencing machine.\\
Read quality control is a step of paramount importance since sequencing-by-synthesis technologies have an intrinsic error rate floating around 0.25\%, meaning that on average, one every four-hundred bases is incorrectly called\cite{Pfeiffer2018}. This is exacerbated by sample processing steps, PCR amplification and glitches in the sequencing procedure itself.\\
One of the main units used to assess sequencing quality is the Phred score. Originally developed for automated Sanger sequencing, the score is computed in an algorithmic fashion for each base sequenced with the following formula\cite{Ewing1998}:
$$Q=-10\log_{10}(e)$$
Where \textit{e} is the estimated probability of the base called being wrong, hence, a higher \textit{Q} score identifies a base called with a lower error probability. Once computed, Phred scores are stored as character strings in ASCII encoding in a standardized file format, known as FASTQ\cite{Cock2010}, also containing the nucleotide-sequence information of each DNA fragment sequenced, known as 'read'.

% embed block of fastq to display almost like an image with associated caption
\begin{lstlisting}[caption=Representative FASTQ lines for one read. Line 1 contains the Illumina-standardized instrument and sample information, line 2 contains the nucleotide sequence read by the machine, line 3 contains a `+` sign which is used to introduce line 4, which contains the quality scores stored in the form of ASCII characters paired with each base.]

@SIM:1:FCX:1:15:6329:1045:GATTACT+GTCTTAAC 1:N:0:ATCCGA
TCGCACTCAACGCCCTGCATATGACAAGACAGAATC
+
<>;##=><9=AAAAAAAAAA9#:<#<;<<<????#=

\end{lstlisting}

Per-base quality was programmatically assessed within the ATAC-seq pipeline by implementing a commonly utilized software known as FastQC\cite{Andrews2010}. Briefly, the program takes FASTQ files and returns a \textit{.html} summary with intuitive plots and metrics useful for the proper evaluation of overall read quality.
The FastQC approach allows the inspection of base quality scores, GC content, sequence length distribution, sequence duplication levels,\textit{k}-mer overrepresentation and contamination of primers and adapters in the sequencing data. Of particular interest are the per-base quality scores, which naturally tend to drop towards the 3' end of reads, adapter content and per-sequence GC content distribution, which should not veer from a normal one and could highligh PCR-related problems\cite{Benjamini2012}.\\
A series of procedures were then applied in a streamlined fashion to decrease the number of low quality fragments and therefore ensure insightful downstream analysis. Namely, after adapter removal, read trimming at 3' ends was performed by \textit{Trim Galore!}, a wrapper for Cutadapt, to avoid the inclusion of bases with a Phred score of less than 20, then reads shorter than 36bp were automatically excluded from FASTQ files in order to preserve alignment integrity and decrease the probability of duplicate mapping. After trimming, another run of FastQC was performed on the quality-checked reads to inspect their quality as a further control. Given the amount of quality control data, MultiQC\cite{Ewels2016} was used to better summarize the output of the abovementioned processes. 

\section{Read alignment to a reference genome}
Once reads are produced by a sequencing platform and checked for their quality, they start to provide biological insigth after their alignment to a reference genome. The process of aligning relatively short reads to an imposingly long genome such as the human one presents a programmatic challenge which entails a balance between accuracy and practicality (e.g. speed), the better of this two aspects is implemented in the form of the Burrows-Wheeler Aligner\cite{Li2009} (BWA). This tool exploits an approach taken from string-matching theory and known as the Burrows-Wheelers Transform\cite{Burrows1994} (BWT), originally developed for data compression purposes. The original transform algorithm is now embodied within three implementations of different nature, BWA-backtrack, BWA-SW and BWA-MEM. BWA-MEM\cite{Li2013} is the latest, while being also the fastest, more precise and more suited for aligning longer (>100 bp) reads.\\
Briefly, the algorithmic operation performed by BWA-MEM is based on a specific data structure known as a\textit{trie}, or more simply a tree-like data structure, very common within string-matching algorithms but very memory-inefficient for longer character strings, such as the human genome. To increase its operational speed, the algorithm takes advantage of a more memory-efficient variant of a trie, an FM-index\cite{Ferragina2000}. The program builds an FM-index of the reference genome, which in the case of this analysis is the hg38 release of the human genome by UCSC. This operation produces a compressed representation of the genome while maintaining the ability to easily interrogate it for query-reference matches thanks to the readily accessible indexed trie structure. For every query that has to be aligned, the trie is traversed top-down while the substrings are confronted with the query. After the reference genome is indexed, the algorithm follows a standard \textit{`seed and extend`} paradigm. Initially, it finds for each query position the longest exact match in the reference covering that specific position, these seeded alignments are termed supermaximal exact matches (SMEMs), which by default have a maximum length of 28bp. To ensure the inclusion of true alignments which might not contain any SMEM, the algorithm also performs a re-seeding procedure. Once query seeds are generated, the program looks for seeds linearly close to each other in order to form \textit{chains}, which are then filtered based on their presence within a longer chain and a lower alignment quality with respect to the longer chain. This procedure is aimed at reducing unsuccessful seed extension at a later step. Once all chains have been identified, seeds within chains are ranked based on the length of the chain they are in and by their own length, then each seed is extended with a banded affine-gap-penalty dynamic programming (DP). Importantly, while extending seeds, BWA-MEM tries to keep track of the best extension score to the end of the query sequence. The difference between the best score reaching the end of the alignment and the local alignment determines whether the final hit is considered to be the more precise end-to-end alignment or the local counterpart in which the seed ends are `soft clipped`, with a preference towards choosing the end-to-end alignment.\\ Since in this particular experimental procedure paired-end reads are produced, it is worth analyzing how BWA-MEM handles the alignment procedure for paired-end reads. BWA-MEM processes reads in batches, and for each batch it estimates the mean and variance of the insert size distribution in order to detect single reads without a mate in a pre-determined distance window around the lone read. If the mate read is unmapped within the window, the algorithm tries to rescue it by aligning it with SSE2-based Smith-Waterman alignment\cite{Farrar2007} (SW). Once lone reads are rescued, hits found from both the single-sequence alignment and the SW alignment procedure are used for pairing. In the ATAC-seq pipeline, default settings were used to run BWA-MEM.
The output produced by the alignment procedure is in Sequence Alignment/Map (SAM) format\cite{Li2009a}, which is a standard, human-readable format containing an optional header section with the information on how the file was generated and how the mapping was obtained, and then an alignment section. The alignment section is composed of a series of informations regarding where and how sequenced reads are aligned along the genome. The file format stores this informations inside specific fields. For instance, the query name is retained in the QNAME field while a bit-wise flag which can be used to further filter down low-quality reads populates the FLAG field. An important readout contained in SAM files is the read mapping quality score, which can be found in the MAPQ field, and describes the phred-scaled posterior probability that the mapping position is wrong. Since SAM files occupy large amounts of memory, they are frequently converted to their machine-readable (i.e. binary) counterpart, known as Binary Alignment/Map (BAM) files, which store the same information in a more memory-efficient, indexed format.  

\section{Removal of multi-mapped reads, PCR duplicates and low-quality reads}
Much like aligning reads on a reference genome helps with gaining biological insight, filtering low-quality reads based on alignment helps with ensuring proper quality within downstream analysis. Importantly, reads might be aligned with varying degrees of confidence on multiple positions along the genome. These instances, known as multi-mappings, can influence later procedures like peak-calling by increasing the total number of reads available, while introducing uncertainty in the procedure itself due to ambiguity. Hence, using SAMtools\cite{Li2009a} \textit{view}, only reads marked as uniquely mapped (MAPQ \neq 0) were kept and on these, additional filtering was performed on the bit-wise flag values, to achieve filtering of unmapped (0x004 flag), lone (0x008) and non-primarily aligned (0x001 flag) reads.\\
Following these initial steps of filtering, duplicated reads are identified with Picard's \textit{markDuplicates} function\cite{Picard2019toolkit}. Duplicates can be generated during alternate phases of the experimental protocol of many NGS techniques, including ATAC-seq, since they can result from improper PCR amplification and/or from an incorrect optical readout from the sequencing machine, by which the fluorescent signal from one cluster on a flow-cell is wrongly identified as one coming from two different clusters, therefore producing two of the same sequences where instead only one was physically present on the flow-cell surface. The bit-wise flag for duplication (0x0400) is then identified by SAMtools and reads carrying it are subsequently removed from the read pool.\\
One further source of contamination, particularly relevant for ATAC-seq experiments, are reads originating from mitochondrial DNA. The portion of genetic code residing inside mithochondria is particularly prone to Tn5 digestion thanks to the lack of chromatin packaging\cite{Bogenhagen2012}, therefore removal of these reads is included in the pipeline. Moreover, reads aligned within regions blacklisted by the ENCODE consortium\cite{Amemiya2019} are also removed; these include portions of the genome with anomalous, unstructured or unusually high signal, and many times involve known repetitive elements. This task is achieved by feeding the pipeline a file containing the genomic coordinates of the blacklisted regions, previously created with BEDtools\cite{Quinlan2010}, and then taking again advantage of SAMtools for the removal of reads falling within the set of coordinates.\\
Additional filtering steps specifically applied in this analysis included the removal of soft-clipped reads, reads aligned with more than four mismatches, reads whose mate had been mapped to another chromosome or that were not paired in a forward-reverse fashion, along with read pairs with an insert size greater than 2Kb.
\section{Peak Calling and Peak Annotation}
\section{Generation of a Consensus peakset}
\section{ATAC-seq Quality Control}
\section{Differential accessibility analysis with the DESeq2 package}
\section{Transcription factor footprinting analysis with TOBIAS}